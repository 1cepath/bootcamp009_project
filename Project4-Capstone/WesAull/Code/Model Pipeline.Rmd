---
title: "Final Full-Scale Modeling"
author: "Wes Aull"
date: "June 18, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(Quandl)
library(quantmod)
library(readr)
library(ggplot2)
library(forecast)
library(randomForest)
library(xts)
library(tseries)
library(timeSeries)
library(e1071)
library(xgboost)
library(Matrix)
library(stringr)
library(caret)
library(car)
library(quantreg)
library(FNN)
library(glmnet)
library(acepack)
library(BayesTree)
library(neuralnet)
library(corrplot)
library(KRLS)
library(factoextra)
library(ggthemes)
library(party)
library(TTR)
library(gridExtra)
library(roll)

Quandl.api_key("w4EHWxgdsJqt9m4Zhvkq")

set.seed(100)
```

***########### Data Import ###########***

Data imported or collapsed to a monthly time series.  Much of the data is released within 7-10
days after the month end.  The latest release comes on the second Friday (potentially 14th) of
each month from U. of Michigan surveys.  I align the data for what is known at the 14th for
predicting forward return.

**Historical S&P 500 and CAPE Import:**

CSV import of the historical 10 year treasury, CPI, and CAPE ratio from Bob Shiller's website and updated from his original work "Market Volatility".  His data reflects the average for a given month.

*1.) Consumer Price Inflation [CPI] (1871 - Present) <Variable Name: CPI>*

i.: broad-measured inflation from a long-constructed historical series.  See Market Volatility for details of construction.

*2.) Long-term Interest Rates for Highly-Secure Bonds [i.e. Treasuries] (1871 - Present) <Variable Name: T10>*

i.: long-term interest rates for highly-secure bonds from a long-constructed historical series, mostly Treasuries with a duration of 10+ year.  See Market Volatility for details of construction.  

*1.) Cyclically Adjusted Price to Earnings Ratio [CAPE] (1881 - Present) <Variable Name: CAPE>*

i.: stock index price divided by the average of ten years of earnings (moving average), adjusted for inflation, from a long-constructed historical series.  See Market Volatility for details of construction.

```{r}
#shiller <- read_csv("C:/Users/Wes Aull/GoogleDrive/Capstone/Data/shiller.csv", 
#    col_types = cols(CAPE = col_number(), 
#        Date = col_date(format = "%m/%d/%Y")))

shiller <- read_csv("~/GoogleDrive/Capstone/Data/shiller.csv", 
    col_types = cols(CAPE = col_number(), 
        Date = col_date(format = "%m/%d/%Y")))

shiller = as.xts(shiller[,2:4], order.by=as.yearmon(shiller$Date))
```

**Quandl Import:**

I use Quandl in downloading data from the Federal Reserve, AAII, U Mich Survey, ISM, Moody's, NYX, CBOE, and select commodity Data.  Some of these variables are complex and have information at several levels, which I try to illuminate below.  The data series imported:

*1.) Monthly spread between 10-Year Treasury and Fed Funds Rate (1954 - Present) <Variable Name: T10YFF>*

i.: lending spread or incentive to borrow short-term and invest/lend long-term.

ii.: spread correlates with the amount of unused capacity in the economy based on the central bank's response to economic conditions.

*2.) Weekly Allowance for Loan & Lease Losses, Large Domestic Chartered Commercial Banks (1985 - Present, Seasonally Adjusted [SA]) <Variable Name: LADCB>*

i.: amount booked on bank financial statements as 'expected' loss on its overall lending portfolio.

ii.: a significant increase in allowance occurs in response to a significant downward shift in economic conditions compared to the banks' past expectations.  A significant decrease occurs in response to a significant upward shift in economic conditions compared to the banks' past experience or expectations.

*3.) Monthly Civilian Unemployment Rate (1948 - Present, SA) <Variable Name: UNRATE>*

i.: amount of labor slack in the economy.

ii.: correlates with aggregate labor and capital slack in the economy.

*4.) 4-Week Moving Weekly Average of Initial Unemployment Claims (1967 - Present, SA) <Variable Name: ICSA>*

i.: amount of labor slack being created in the economy.

*5.) Monthly Change in Labor Market Conditions Index (1976 - Present, SA) <Variable Name: LMCI>*

i.: Derived from a dynamic factor model that extracts primary common variation from 19 seasonally adjusted labor market indicators. Subject to decent amount of revision over time due to new, revised information along with the model's Kalman smoother.  I've observed changes in this series and they don't seem to vary significantly...but this deserves attention.

*6.) CBOE's S&P 100 Volatility Index (1986 - Present) <VXO_Open, VXO_High, VXO_Low, VXO_Close>*

i.: calculation of volatility using a blend of prices of options on the S&P 100.

*7.) weekly AAII Investor Sentiment Survey (1987 - Present.) <AAII_Bullish, AAII_Neutral, AAII_Bearish, AAII_Total, AAII_Bullish8WKMA, AAII_BullBearSpead, AAII_BullAvg, AAII_BullAvgadStDev, AAII_BullAvgsubStDev>*

i.: percentage of investors who are bullish, bearish, and neutral on the market for the following 6 months.

*8.) Monthly NYX Margin Data (1959 - Present) <NYX_MD, NYX_FCC, NYX_CB>*

i.: amount of margin debt, free credit cash accounts, and credit balances in margin accounts for the NYSE.

*9.) Monthly Baa [Lowest Investment Grade Tier] Corporate Bond Yield (1919 - Present) <Variable Name: BAA>*

i.: cost of capital for corporate borrowing in the lowest quality of investment grade corporate bonds.

ii.: significant changes occurs in response to a significant changes in expectations of economic conditions compared to past expectations.

*10.) Daily Continuous Contract #3 for Copper Futures (1959 - Present) <Variable Name: HG3>*

i.: copper is the 3rd most widely used metal in the world.  It has a wide number of commercial applications (circuit boards, solder, microwave ovens, integrated circuits, electromagnets, wiring, and piping) that span residential, commercial, and industrial end-users in the economy.  Aluminum and iron would be other commodity candidates that reflect overall demand from economic activity.  Iron's use is primarily industrial and not as diverse in application.  Aluminum would be a reasonable alternative but doesn't have the same level of activity reflected by infrastructure/real estate activity as compared to copper.

*11.) Average Weekly Overtime Hours of Production and Nonsupervisory Employees: Manufacturing (1956 - Present, SA) <Variable Name: OVT_MAN>*

i.: reflects slack (or lack of) in the economy.

*12.) Average Weekly Hours of Production and Nonsupervisory Employees: Manufacturing (1939 - Present, SA) <Variable Name: WKH_MAN>*

i.: reflects slack (or lack of) in the economy.

*13.) Monthly ISM Manufacturing New Orders Index (1948 - Present, SA) <Variable Name: IS_MAN_NEWORD>*

i.: reflects changes in demand conditions before they are reflected in production / sales.

*14.) Monthly University of Michigan Consumer Survey SOC32: Expected Change in Prices During Next Year (1978 - Present) <Soc32_Down, Soc32_Same, Soc32_Up2, Soc32_Up4, Soc32_Up5, Soc32_Up9, Soc32_Up14, Soc32_Up15Plus, Soc32_Mean, Soc32_Var, Soc32_SD, Soc32_25thP, Soc32_Median, Soc32_Soc32_75thP, Soc32_InterQuart>*

*15.) Monthly University of Michigan Consumer Survey SOC28: Business Conditions Expected During Next Year (1978 - Present) <Soc28_Good, Soc28_Uncertain, Soc28_Bad, Soc28_Relative>*

*16.) Monthly University of Michigan Consumer Survey SOC25: Current Business Conditions Compared with Year Ago (1978 - Present) <Soc25_Better, Soc25_Same, Soc25_Worse, Soc25_DK, Soc25_Relative>*
ougf
*17.) Monthly University of Michigan Consumer Survey SOC5: Components of the Index of Consumer Sentiment (1978 - Present) <Soc5_PF_Curr, Soc5_PF_Exp, Soc5_BusCond_12M, Soc5_BusCond_5Y, Soc5_BuyCondition, Soc5_CurrIndex, Soc5_ExpIndex>*

*18.) Monthly Private Housing Units Authorized by Building Permits (1960 - Present) <Variable Name: Res_Permit>*

*19.) Monthly Private Housing Units Authorized by Building Permits in Structures with 1 Unit (1960 - Present) <Variable Name: SingleRes_Permit>*

*20.) Quarterly Net Percentage of Domestic Banks Tightening Standards for Commercial and Industrial Loans to Small Firms (1990 - Present) <Variable Name: Lend_CI_Small>*


```{r}
data <- Quandl(c('FRED/T10YFFM','FRED/ALLLCBM027SBOG','FRED/UNRATE',
                 'FRED/IC4WSA','FRED/FRBLMCI','CBOE/VXO','AAII/AAII_SENTIMENT',
                 'NYXDATA/MARKET_CREDIT','MOODY/BAAYLD','CHRIS/CME_HG2.4','FRED/AWOTMAN',
                 'FRED/AWHMAN','ISM/MAN_NEWORDERS', 'UMICH/SOC32','UMICH/SOC28',
                 'UMICH/SOC25','UMICH/SOC5','FRED/PERMIT','FRED/PERMIT1','FRED/DRTSCIS'),
                  type = 'xts', collapse= 'monthly')

a = c("T10YFF","LADCB","UNRATE","ICSA","LMCI","VXO_Open","VXO_High","VXO_Low","VXO_Close",
                "AAII_Bullish","AAII_Neutral","AAII_Bearish","AAII_Total","AAII_Bullish8WKMA","AAII_BullBearSpread",
                "AAII_BullAvg","AAII_AvgStDevA","AAII_AvgStDevS","AAII_Del1", "AAII_Del2", "AAII_Del3", "NYX_MD",
                "NYX_FCC", "NYX_CB", "BAA","HG3","OVT_MAN","WKH_MAN","ISM_Del1","ISM_Del2","ISM_Del3","ISM_MAN_NEWORD",
                "ISM_MAN_NEWORD_DIFF","Soc32_Down","Soc32_Same","Soc32_Up2","Soc32_Up4","Soc32_Up5","Soc32_Up9",
                "Soc32_Up14","Soc32_Up15Plus","Soc32_Del1","Soc32_Del2","Soc32_Mean","Soc32_Var","Soc32_SD","Soc32_25thP",
                "Soc32_Median","Soc32_75thP","Soc32_InterQuart","Soc28_Good","Soc28_Uncertain","Soc28_Bad", "Soc28_Del1",
                "Soc28_Del2","Soc28_Relative","Soc25_Better","Soc25_Same","Soc25_Worse","Soc25_DK","Soc25_Relative",
                "Soc5_PF_Curr","Soc5_PF_Exp","Soc5_BusCond_12M","Soc5_BusCond_5Y","Soc5_BuyCondition","Soc5_CurrIndex",
                "Soc5_ExpIndex","Res_Permit","SingleRes_Permit","Lend_CI_Small")

names(data) = a

#Several monthly series are released longer than 4 weeks after the close of the month.  I lag their values to reflect what is known alongside the release of the remaining variables..

data$NYX_MD = lag(data$NYX_MD,1)
data$NYX_FCC = lag(data$NYX_FCC,1)
data$NYX_CB =  lag(data$NYX_CB,1)
data$Res_Permit = lag(data$Res_Permit,1)
data$SingleRes_Permit = lag(data$SingleRes_Permit,1)
data$Lend_CI_Small = lag(data$Lend_CI_Small,1)

#Next, I join the Shiller import data with the Quandl data.

data = merge(shiller,data,join='left',fill='NA')

#Lastly, I lag the entire series by one month because the month marked corresponds to the month that the activity reflects.  #All the variables are reported within 2 weeks after the close of the month (with the adjustment made above for the series that take longer than 4 weeks to release).  We will examine forward return from the 14th of the following month when we merge the S&P price data further below.



```
**Daily S&P OHLC & Volume Import:**

CSV import of daily OHLC and volume of S&P 500 since 1950 to facilitate more accurate return metrics than the monthly average date in the CAPE csv.

```{r}
#GSPC <- read_csv("C:/Users/Wes Aull/GoogleDrive/Capstone/Data/^GSPC.csv", 
#                 col_types = cols(Date = col_date(format = "%m/%d/%Y"), 
#                                  Volume = col_number()))

GSPC <- read_csv("~/GoogleDrive/Capstone/Data/^GSPC.csv", 
    col_types = cols(Date = col_date(format = "%m/%d/%Y"), 
        Volume = col_number()))

GSPC = as.xts(GSPC[,2:7], order.by=GSPC$Date)
GSPC$RSI = RSI(as.vector(GSPC$Close), n = 100)

GSPC = lag(GSPC,k=-12)
#use lag from timeSeries package to align data.

```


```{r}
GSPC$Close = log(GSPC$Close)
GSPC = to.period(GSPC,period="months")
GSPC$RSI_6M = RSI(as.vector(GSPC$GSPC.Close), n = 6)
GSPC$RSI_8M = RSI(as.vector(GSPC$GSPC.Close), n = 8)
GSPC = GSPC[1:(nrow(GSPC)-1),]
index(GSPC) = as.yearmon(index(GSPC))

GSPC_18M_Ret = lag(diff(GSPC$GSPC.Close, lag = 18), k=-18)
GSPC_12M_Ret = lag(diff(GSPC$GSPC.Close, lag = 12), k=-12)
GSPC_12M_Trail_Ret = diff(GSPC$GSPC.Close,lag = 12)
GSPC_6M_Ret = lag(diff(GSPC$GSPC.Close, lag = 6), k=-6)
GSPC_3M_Ret = lag(diff(GSPC$GSPC.Close, lag = 3), k=-3)
GSPC_1M_Ret = lag(diff(GSPC$GSPC.Close, lag = 1), k=-1)

GSPC_18M_Ret = GSPC_18M_Ret[complete.cases(GSPC_18M_Ret),]
GSPC_12M_Ret = GSPC_12M_Ret[complete.cases(GSPC_12M_Ret),]
GSPC_12M_Trail_Ret = GSPC_12M_Trail_Ret[complete.cases(GSPC_12M_Trail_Ret),]
GSPC_6M_Ret = GSPC_6M_Ret[complete.cases(GSPC_6M_Ret),]
GSPC_3M_Ret = GSPC_3M_Ret[complete.cases(GSPC_3M_Ret),]
GSPC_1M_Ret = GSPC_1M_Ret[complete.cases(GSPC_1M_Ret),]

GSPC_Quarterly = to.period(GSPC,period="quarters")
GSPC_Quarterly = GSPC_Quarterly[1:(nrow(GSPC_Quarterly)-1),]
GSPC_Quarterly_Ret = lag(diff(GSPC_Quarterly$GSPC.Close, lag = 1),k=-1)
GSPC_Quarterly_Ret = GSPC_Quarterly_Ret[complete.cases(GSPC_Quarterly_Ret),]

GSPC_Yearly = to.period(GSPC, period='years')
GSPC_Yearly = GSPC_Yearly[1:(nrow(GSPC_Yearly)-1),]
GSPC_Yearly_Ret = lag(diff(GSPC_Yearly$GSPC.Close,1),k=-1)
GSPC_Yearly_Ret = GSPC_Yearly_Ret[complete.cases(GSPC_Yearly_Ret),]

## Additional of technical factors for 12M modeling
GSPC_RSI = GSPC$RSI_6M
GSPC_RSI$RSI_8M = GSPC$RSI_8M

plot(GSPC_RSI$RSI_8M)

```


```{r}
window_length = 72
exp_decay <- 0.95 ^ (window_length:1)
a = data$LADCB[complete.cases(data$LADCB),]
a = ROC(a$LADCB,3,type='discrete')
data$LADCB = NULL
a = a$LADCB[complete.cases(a$LADCB),]
a = roll_scale(a$LADCB[complete.cases(a$LADCB),],width=window_length,min_obs = 12)
plot(exp(a))
plot(1.3^a)
a=1.3^a
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 72
exp_decay <- 0.95 ^ (window_length:1)
a = data$ICSA[complete.cases(data$ICSA),]
a = ROC(a$ICSA,3,type='discrete')
data$ICSA = NULL
a = a$ICSA[complete.cases(a$ICSA),]
a = roll_scale(a$ICSA[complete.cases(a$ICSA),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 120
exp_decay <- 0.95 ^ (window_length:1)
a = data$NYX_MD[complete.cases(data$NYX_MD),]
a = ROC(a$NYX_MD,60,type='discrete')
data$NYX_MD = NULL
a = a$NYX_MD[complete.cases(a$NYX_MD),]
a = roll_scale(a$NYX_MD[complete.cases(a$NYX_MD),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 48
exp_decay <- 0.95 ^ (window_length:1)
a = data$SingleRes_Permit[complete.cases(data$SingleRes_Permit),]
a = ROC(a$SingleRes_Permit,48,type='discrete')
data$SingleRes_Permit = NULL
a = a$SingleRes_Permit[complete.cases(a$SingleRes_Permit),]
a = roll_scale(a$SingleRes_Permit[complete.cases(a$SingleRes_Permit),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 48
exp_decay <- 0.95 ^ (window_length:1)
a = data$T10[complete.cases(data$T10),]
data$T10 = NULL
a = a$T10[complete.cases(a$T10),]
a = roll_scale(a$T10[complete.cases(a$T10),],width=window_length,min_obs = 12)
plot(a) 
data = merge(data,a,join='left',fill='NA')
```




```{r}
window_length = 24
exp_decay <- 0.95 ^ (window_length:1)
a = data$WKH_MAN[complete.cases(data$WKH_MAN),]
a = ROC(a$WKH_MAN,6,type='discrete')
data$WKH_MAN = NULL
a = a$WKH_MAN[complete.cases(a$WKH_MAN),]
a = roll_scale(a$WKH_MAN[complete.cases(a$WKH_MAN),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 24
exp_decay <- 0.95 ^ (window_length:1)
a = data$Soc32_Up14[complete.cases(data$Soc32_Up14),]
a = rollmeanr(a$Soc32_Up14,12,fill=NA)
a = a$Soc32_Up14[complete.cases(a$Soc32_Up14),]
a = ROC(a$Soc32_Up14,12,type='discrete')
data$Soc32_Up14 = NULL
a = a$Soc32_Up14[complete.cases(a$Soc32_Up14),]
a = roll_scale(a$Soc32_Up14[complete.cases(a$Soc32_Up14),],width=window_length,min_obs = 12)
plot(a)
plot(1.5^(a))
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 24
exp_decay <- 0.95 ^ (window_length:1)
a = data$Soc32_Mean[complete.cases(data$Soc32_Mean),]
a = rollmeanr(a$Soc32_Mean,12,fill=NA)
a = data$Soc32_Mean[complete.cases(data$Soc32_Mean),]
a = ROC(a$Soc32_Mean,18,type='discrete')
data$Soc32_Mean = NULL
a = a$Soc32_Mean[complete.cases(a$Soc32_Mean),]
a = roll_scale(a$Soc32_Mean[complete.cases(a$Soc32_Mean),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 24
exp_decay <- 0.95 ^ (window_length:1)
a = data$CPI[complete.cases(data$CPI),]
a = rollmeanr(a$CPI,12,fill=NA)
a = a$CPI[complete.cases(a$CPI),]
a = ROC(a$CPI,18,type='discrete')
data$CPI = NULL
a = a$CPI[complete.cases(a$CPI),]
a = roll_scale(a$CPI[complete.cases(a$CPI),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
window_length = 48
exp_decay <- 0.95 ^ (window_length:1)
a = GSPC_RSI$RSI_8M[complete.cases(GSPC_RSI$RSI_8M),]
a = rollmeanr(a$RSI_8M,12,fill=NA)
a = a$RSI_8M[complete.cases(a$RSI_8M),]
a = ROC(a$RSI_8M,24,type='discrete')
GSPC_RSI$RSI_8M = NULL
a = a$RSI_8M[complete.cases(a$RSI_8M),]
a = roll_scale(a$RSI_8M[complete.cases(a$RSI_8M),],width=window_length,min_obs = 12)
plot(a)
data = merge(data,a,join='left',fill='NA')
```


```{r}
#data$UNRATE_TD12M = diff(data$UNRATE, diff = 3, lag = 12)
#data$Res_Permit_TD12M = diff(data$Res_Permit, diff = 3, lag = 12)

return_data = merge(data,GSPC_RSI,join='left',fill='NA')

complete_data = return_data

#Deleting irrelevant or repetitive data.
complete_data$AAII_Del1 = NULL
complete_data$AAII_Del2 = NULL
complete_data$AAII_Del3 = NULL
complete_data$ISM_Del1 = NULL
complete_data$ISM_Del2 = NULL
complete_data$ISM_Del3 = NULL
complete_data$Soc32_Del1 = NULL
complete_data$Soc32_Del2 = NULL
complete_data$Soc28_Del1 = NULL
complete_data$Soc28_Del2 = NULL
complete_data$Lend_CI_Small = NULL
complete_data$HG3 = NULL
complete_data$VXO_Open = NULL
complete_data$VXO_Close = NULL
complete_data$VXO_High = NULL
complete_data$VXO_Low = NULL
complete_data$AAII_Bullish8WKMA = NULL
complete_data$NYX_FCC = NULL
complete_data$AAII_Total = NULL
complete_data$AAII_BullBearSpread = NULL
complete_data$'BullAvgaddStDev' = NULL
complete_data$BullAvgsubStDev = NULL
complete_data$Soc25_DK = NULL
complete_data$Soc25_Relative = NULL
complete_data$AAII_BullAvg = NULL
complete_data$AAII_AvgStDevA = NULL
complete_data$AAII_AvgStDevS = NULL
complete_data$AAII_Neutral = NULL
complete_data$Soc32_Same = NULL
complete_data$Soc32_25thP = NULL
complete_data$Soc32_SD = NULL
complete_data$Soc32_InterQuart = NULL
complete_data$Soc32_Up4 = NULL
complete_data$Soc32_Up5 = NULL
complete_data$Soc32_Up2 = NULL
complete_data$CurrIndex = NULL
complete_data$Soc5_PF_Curr = NULL
complete_data$Soc25_Same = NULL
complete_data$Soc25_Worse = NULL
complete_data$Soc5_BuyCondition = NULL
#complete_data$Soc5_ExpIndex = NULL
complete_data$Soc5_CurrIndex = NULL
#complete_data$Soc5_BusCond_5Y = NULL
complete_data$Soc5_BusCond_12M = NULL
complete_data$Soc5_PF_Exp = NULL
complete_data$Soc32_Up15Plus = NULL
#complete_data$Soc32_Mean = NULL
#complete_data$CPI = NULL
#complete_data$RSI_20M = NULL
complete_data$Soc28_Good = NULL
complete_data$ISM_MAN_NEWORD = NULL
#complete_data$Soc32_Up14 = NULL
#complete_data$Soc32_75thP = NULL
#complete_data$AAII_Bullish = NULL
#complete_data$T10 = NULL

#complete_data$
#complete_data$Res_Permit = NULL

#complete_data$CPI = ROC(complete_data$CPI,6)
#complete_data$NYX_CB = ROC(complete_data$NYX_CB,6)
#complete_data$BAA = ROC(complete_data$BAA,12)
#complete_data$Res_Permit = ROC(complete_data$Res_Permit,12)

#complete_data$HG3 = lag(ROC(complete_data$HG3,6),k=-6)
#complete_data$VXO_Close = lag(ROC(complete_data$VXO_Close,6),k=-6)

complete_data = complete_data[complete.cases(complete_data),]

#window_length = 48
#exp_decay <- 0.95 ^ (window_length:1)
#complete_data = ROC(complete_data,6,type='discrete')
#complete_data = complete_data[complete.cases(complete_data),]
#complete_data = roll_scale(complete_data,width=window_length,min_obs = 12)
#complete_data = complete_data[complete.cases(complete_data),]

complete_data = merge(complete_data,GSPC_6M_Ret,join='left',fill='NA')
complete_data = complete_data[complete.cases(complete_data),]
complete_data$GSPC.Close = scale(complete_data$GSPC.Close)

```

Set out of sample.  I use 1/3 of the data set as out of sample to contain an entire cycle for testing results.

```{r}
L <- nrow(complete_data)-120
train.index = seq(1,L,by=1)
test.index = seq((L+1),nrow(complete_data),by=1)
```


```{r}
preProcessParameters = preProcess(coredata(complete_data[,1:(ncol(complete_data)-1)]), method = c('center','scale','pca'))
complete_PCA_data = as.xts(predict(preProcessParameters,coredata(complete_data)),order.by=index(complete_data))

## Create model and assess accuracy on train/test set.
lr_pca = lm(GSPC.Close ~ ., complete_PCA_data[train.index,])
summary(lr_pca)
train_pred_PCA = predict(lr_pca,complete_PCA_data[train.index,2:(ncol(complete_PCA_data))])
test_pred_PCA = predict(lr_pca,complete_PCA_data[test.index,2:(ncol(complete_PCA_data))])
accuracy(as.vector(train_pred_PCA),complete_PCA_data[train.index,1],)
accuracy(as.vector(test_pred_PCA),complete_PCA_data[test.index,1],)
plot(lr_pca)

## Collect and visualize residuals from the train and test sets for analysis.
resid_lrpca = data.frame(complete_PCA_data[train.index,1],lr_pca$fitted.values,lr_pca$residuals,row.names = index(complete_data[train.index]))
colnames(resid_lrpca) = c('actual','fitted','residual')
ggplot(resid_lrpca,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Train Residual Plot') + theme_dark()

resid_lrpca_test = data.frame(complete_PCA_data[test.index,1],test_pred_PCA,(complete_PCA_data[test.index,1]-test_pred_PCA),row.names = index(complete_data[test.index]))
colnames(resid_lrpca_test) = c('actual','fitted','residual')
ggplot(resid_lrpca_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Test Residual Plot') + theme_dark()
```
PCA results underperform in all model testing to this point.  It appears that variables with small variance (but significant signal) could be getting drowned out.

```{r}
preProcessParameters = preProcess(coredata(complete_data[,1:(ncol(complete_data)-1)]), method = c('center','scale'))
complete_stand_data = as.xts(predict(preProcessParameters,coredata(complete_data)),order.by=index(complete_data))

lr = lm(GSPC.Close ~ ., complete_stand_data[train.index])
summary(lr)
train_pred_lr = predict(lr,complete_stand_data[train.index,1:(ncol(complete_stand_data)-1)])
test_pred_lr = predict(lr,complete_stand_data[test.index,1:(ncol(complete_stand_data)-1)])
accuracy(as.vector(train_pred_lr),complete_stand_data[train.index,ncol(complete_stand_data)])
accuracy(as.vector(test_pred_lr),complete_stand_data[test.index,ncol(complete_stand_data)])
plot(lr)

## Collect and visualize residuals from the train and test sets for analysis.
resid_lr = data.frame(complete_stand_data[train.index,ncol(complete_stand_data)],lr$fitted.values,lr$residuals,row.names = index(complete_stand_data[train.index]))
colnames(resid_lr) = c('actual','fitted','residual')
ggplot(resid_lr,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Train Residual Plot') + theme_dark()

resid_lr_test = data.frame(complete_stand_data[test.index,ncol(complete_stand_data)],test_pred_lr,(complete_stand_data[test.index,ncol(complete_stand_data)]-test_pred_lr),row.names = index(complete_data[test.index]))
colnames(resid_lr_test) = c('actual','fitted','residual')
ggplot(resid_lr_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Test Residual Plot') + theme_dark()

c_lr = cor(complete_stand_data)
corrplot(c_lr)
mean(complete_data$GSPC.Close)
sd(complete_data$GSPC.Close)
```
The linear regression model is one of the very few models capable of extrapolating for this large of an out of sample (and for one of the more heteregenous periods compared to the training set).


```{r}
model.empty = lm(GSPC.Close ~ 1, data = complete_stand_data[train.index]) #The model with an intercept ONLY.
model.full = lm(GSPC.Close ~ . - Soc5_ExpIndex, data = complete_stand_data[train.index]) #The model with ALL variables.
scope = list(lower = formula(model.empty), upper = formula(model.full))

forwardAIC = step(model.empty, scope, direction = "forward", k = 2, verbose = FALSE, trace = 0)
backwardAIC = step(model.full, scope, direction = "backward", k = 2, verbose = FALSE, trace = 0)
#bothAIC.empty = step(model.empty, scope, direction = "both", k = 2)
#bothAIC.full = step(model.full, scope, direction = "both", k = 2)
#summary(bothAIC.full)
summary(forwardAIC)
train_pred_forward = predict(forwardAIC,complete_stand_data[train.index,1:(ncol(complete_stand_data)-1)])
test_pred_forward = predict(forwardAIC,complete_stand_data[test.index,1:(ncol(complete_stand_data)-1)])
accuracy(as.vector(train_pred_forward),complete_stand_data[train.index],(ncol(complete_stand_data)))
accuracy(as.vector(test_pred_forward),complete_stand_data[test.index,(ncol(complete_stand_data))])
summary(backwardAIC)
train_pred_backward = predict(backwardAIC,complete_stand_data[train.index,1:(ncol(complete_stand_data)-1)])
test_pred_backward = predict(backwardAIC,complete_stand_data[test.index,1:(ncol(complete_stand_data)-1)])
accuracy(as.vector(train_pred_backward),complete_stand_data[train.index],(ncol(complete_stand_data)))
accuracy(as.vector(test_pred_backward),complete_stand_data[test.index,(ncol(complete_stand_data))])

resid_forwlr_test = data.frame(complete_stand_data[test.index,ncol(complete_stand_data)],test_pred_forward,(complete_stand_data[test.index,ncol(complete_stand_data)]-test_pred_forward),row.names = index(complete_data[test.index]))
colnames(resid_forwlr_test) = c('actual','fitted','residual')
ggplot(resid_forwlr_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Test Residual Plot') + theme_dark()

```




```{r}
glm_alph = .7
grid = 10^seq(5, -2, length = 100)
x_stand = sparse.model.matrix(GSPC.Close ~ ., data = complete_stand_data)
y_stand = as.matrix(complete_stand_data[,ncol(complete_stand_data)], rownames.force = index(complete_stand_data))

ridge.models = glmnet(x_stand[train.index, ], y_stand[train.index], alpha = glm_alph, lambda = grid)

# Coefficients across Lambda Parameter space.
plot(ridge.models, xvar = "lambda", label = TRUE, main = "Ridge Regression")

cv.ridge.out = cv.glmnet(x_stand[train.index,], y_stand[train.index,], alpha = glm_alph, nfolds = 10, lambda = grid)

# Plot of Mean-Squared Error across lambda parameter space / optimal value.
plot(cv.ridge.out, main = "Ridge Regression\n")
bestlambda.ridge = cv.ridge.out$lambda.min
bestlambda.ridge
log(bestlambda.ridge)

ridge_reg_train = predict(ridge.models, s = bestlambda.ridge, newx = x_stand[train.index, ])
ridge_reg_test = predict(ridge.models, s = bestlambda.ridge, newx = x_stand[test.index, ])

ridge.out = glmnet(x_stand, y_stand, alpha = glm_alph)
predict(ridge.out, type = "coefficients", s = bestlambda.ridge)

print(accuracy(as.vector(ridge_reg_train),y_stand[train.index,]))
print(accuracy(as.vector(ridge_reg_test),y_stand[test.index,]))

## Collect and visualize residuals from the train and test sets for analysis.
resid_ridge = data.frame(y_stand[train.index,], ridge_reg_train, (y_stand[train.index,] - ridge_reg_train), row.names = index(y_stand[train.index]))
colnames(resid_ridge) = c('actual','fitted','residual')
ggplot(resid_ridge,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Train Residual Plot') + theme_dark()

resid_ridge_test = data.frame(y_stand[test.index,], ridge_reg_test, (y_stand[test.index,] - ridge_reg_test),row.names = index(y_stand[test.index]))
colnames(resid_ridge_test) = c('actual','fitted','residual')
ggplot(resid_ridge_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Test Residual Plot') + theme_dark()    

```



```{r}
n <- names(complete_data[,1:ncol(complete_data)])
f <- as.formula(paste("GSPC.Close ~", paste(n[!n %in% "GSPC.Close"], collapse = " + ")))
nn <- neuralnet(f,data=complete_data[train.index,],hidden=c(5,3),linear.output=F,threshold=.0001,
                learningrate = .25 ,algorithm = 'rprop+')
plot(nn)
train_pred_nn = compute(nn, complete_data[train.index,1:(ncol(complete_stand_data)-1)])
test_pred_nn = compute(nn, complete_data[test.index,1:(ncol(complete_stand_data)-1)])
print(accuracy(as.vector(train_pred_nn$net.result),complete_data[train.index,ncol(complete_stand_data)]))
print(accuracy(as.vector(test_pred_nn$net.result), complete_data[test.index,ncol(complete_stand_data)]))
```


```{r}
## Create model and assess accuracy on train/test set.
rf = randomForest(GSPC.Close ~ ., complete_data[train.index])
varImpPlot(rf)
rf
train_pred_rf = predict(rf, complete_data[train.index,1:(ncol(complete_data)-1)])
test_pred_rf = predict(rf, complete_data[test.index,1:(ncol(complete_data)-1)])
accuracy(as.vector(train_pred_rf),complete_data[train.index,ncol(complete_data)])
accuracy(as.vector(test_pred_rf), complete_data[test.index,ncol(complete_data)])

## Collect and visualize residuals from the train and test sets for analysis.
resid_rf = data.frame(rf$y,rf$predicted,(rf$y - rf$predicted),row.names = index(complete_data[train.index]))
colnames(resid_rf) = c('actual','fitted','residual')
ggplot(resid_rf,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Train Residual Plot') + theme_dark()

resid_rf_test = data.frame(complete_data[test.index,ncol(complete_data)],test_pred_rf,(complete_data[test.index,ncol(complete_data)]-test_pred_rf),row.names = index(complete_data[test.index]))
colnames(resid_rf_test) = c('actual','fitted','residual')
ggplot(resid_rf_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Test Residual Plot') + theme_dark()
```
Random forest extrapolates very poorly into the new period with increased volatility.  Note the difference in negative fitted values versus actual (the response variable is scaled in standard deviations) in the train residuals chart.

In the test chart, it's even more obvious how bad Random Forest is at predicting behavior outside of the state space that it was trained in (incapable of extrapolating).  

```{r}
## Create model and assess accuracy on train/test set.
svr = svm(GSPC.Close ~ .,complete_data[train.index],epsilon=.1,type='eps-regression',cross=5)
svr
train_pred_svr = predict(svr, complete_data[train.index,1:(ncol(complete_data)-1)])
test_pred_svr = predict(svr, complete_data[test.index,1:(ncol(complete_data)-1)])
accuracy(as.vector(train_pred_svr),complete_data[train.index,(ncol(complete_data))])
accuracy(as.vector(test_pred_svr), complete_data[test.index,(ncol(complete_data))])

## Collect and visualize residuals from the train and test sets for analysis.
resid_svr = data.frame(complete_data[train.index,(ncol(complete_data))],svr$fitted,svr$residuals,row.names = index(complete_data[train.index]))
colnames(resid_svr) = c('actual','fitted','residual')
ggplot(resid_svr,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Train Residual Plot') + theme_dark()

resid_svr_test = data.frame(complete_data[test.index,(ncol(complete_data))],test_pred_svr,(complete_data[test.index,(ncol(complete_data))] - test_pred_svr),row.names = index(complete_data[test.index]))
colnames(resid_svr_test) = c('actual','fitted','residual')
ggplot(resid_svr_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Test Residual Plot') + theme_dark()
```
Poor job of extrapolation.

```{r}
sparse_matrix = sparse.model.matrix(GSPC.Close ~ .-1, data = complete_data)
output_vector = as.vector(complete_data[,ncol(complete_data)])
df_train = sparse_matrix[train.index,,drop=FALSE]
df_test = sparse_matrix[test.index,,drop=FALSE]

para = list(booster = "gbtree", objective = "reg:linear", eta=.25, gamma=0, max_depth=17, min_child_weight=1, subsample=1, colsample_bytree=1)

xgbcv <- xgb.cv( params = para, data = df_train,label = output_vector[train.index], nrounds = 100, nfold = 5, showsd = T, stratified = T, print_every_n = 10, early_stopping_rounds = 20, maximize = F)
print(xgbcv,verbose=TRUE)

xgb_model = xgboost(params = para, data=df_train,label = output_vector[train.index], nrounds = xgbcv$best_iteration, verbose = 0)

#train_pred_xgb = predict(xgb_model, complete_data[train.index,1:56])
#test_pred_xgb = predict(xgb_model, complete_data[test.index,1:56])
#accuracy(as.vector(train_pred_xgb),complete_data[train.index,57])
#accuracy(as.vector(test_pred_xgb), complete_data[test.index,57])

```


```{r}
knn_reg = knn.reg(as.vector(complete_stand_data$Soc25_Better),y=y_stand,k=3)
knn_reg
accuracy(as.vector(knn_reg$pred),y_stand)

resid_knn = data.frame(y_stand,knn_reg$pred,knn_reg$residuals)
colnames(resid_knn) = c('actual','fitted','residual')
ggplot(resid_knn,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Train Residual Plot') + theme_dark()
```


```{r}
krls_reg = krls(x_stand[train.index,],y_stand[train.index])

krls_pred_train = predict(krls_reg, x_stand[train.index,])
krls_pred_test = predict(krls_reg, x_stand[test.index,])

print(accuracy(as.vector(krls_pred_train$fit),y_stand[train.index]))
print(accuracy(as.vector(krls_pred_test$fit),y_stand[test.index]))

## Collect and visualize residuals from the train and test sets for analysis.
krls_train_resid = data.frame(y_stand[train.index], krls_pred_train$fit, (y_stand[train.index] - krls_pred_train$fit), row.names = index(y_stand[train.index]))
colnames(krls_train_resid) = c('actual','fitted','residual')
ggplot(krls_train_resid,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Train Residual Plot') + theme_dark()

krls_test_resid = data.frame(y_stand[test.index], krls_pred_test$fit, (y_stand[test.index] - krls_pred_test$fit),row.names = index(y_stand[test.index]))
colnames(krls_test_resid) = c('actual','fitted','residual')
ggplot(krls_test_resid,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Test Residual Plot') + theme_dark()
```



```{r}
quant_reg = rq(GSPC.Close ~ .,tau=.53,complete_stand_data[train.index,])
quant_reg_pred_test = predict(quant_reg,complete_stand_data[test.index,1:(ncol(complete_stand_data)-1)])
print(accuracy(quant_reg$fitted.values,quant_reg$y))
print(accuracy(quant_reg_pred_test,complete_stand_data[test.index,ncol(complete_stand_data)]))

## Collect and visualize residuals from the train and test sets for analysis.
qr_train_resid = data.frame(quant_reg$y, quant_reg$fitted.values, quant_reg$residuals, row.names = index(complete_stand_data[train.index,]))
colnames(qr_train_resid) = c('actual','fitted','residual')
ggplot(qr_train_resid,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Train Residual Plot') + theme_dark()

qr_test_resid = data.frame(complete_stand_data[test.index,ncol(complete_stand_data)], quant_reg_pred_test, (complete_stand_data[test.index,ncol(complete_stand_data)] - quant_reg_pred_test),row.names = index(complete_stand_data[test.index,]))
colnames(qr_test_resid) = c('actual','fitted','residual')
ggplot(qr_test_resid,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) +
  ggtitle(label = 'Test Residual Plot') + theme_dark()

```


```{r}
## Create model and assess accuracy on train/test set.
rf = randomForest(GSPC.Close ~ LADCB + CAPE + NYX_MD + T10YFF + UNRATE + AAII_Bullish + OVT_MAN + Soc32_Up14 + Soc28_Bad + RSI_6M + Res_Permit + BAA + CPI + WKH_MAN, complete_data[train.index])
varImpPlot(rf)
rf
train_pred_rf = predict(rf, complete_data[train.index,1:(ncol(complete_data)-1)])
test_pred_rf = predict(rf, complete_data[test.index,1:(ncol(complete_data)-1)])
accuracy(as.vector(train_pred_rf), complete_data[train.index,ncol(complete_data)])
accuracy(as.vector(test_pred_rf), complete_data[test.index,ncol(complete_data)])

## Collect and visualize residuals from the train and test sets for analysis.
resid_rf = data.frame(rf$y,rf$predicted,(rf$y - rf$predicted),row.names = index(complete_data[train.index]))
colnames(resid_rf) = c('actual','fitted','residual')
ggplot(resid_rf,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Train Residual Plot') + theme_dark()

resid_rf_test = data.frame(complete_data[test.index,ncol(complete_data)],test_pred_rf,(complete_data[test.index,ncol(complete_data)]-test_pred_rf),row.names = index(complete_data[test.index]))
colnames(resid_rf_test) = c('actual','fitted','residual')
ggplot(resid_rf_test,aes(x=fitted,y=actual,colour=residual)) + geom_point() + scale_colour_gradientn(colours=rainbow(4)) + ggtitle(label = 'Test Residual Plot') + theme_dark()
```



```{r}
ct = ctree(GSPC.Close ~ .,complete_data[train.index], controls = ctree_control(maxsurrogate = 0, mtry = 0))
ct
plot(ct)

train_pred_ct = predict(ct, complete_data[train.index,1:(ncol(complete_data)-1)])
test_pred_ct = predict(ct, complete_data[test.index,1:(ncol(complete_data)-1)])
accuracy(as.vector(train_pred_ct), complete_data[train.index,ncol(complete_data)])
accuracy(as.vector(test_pred_ct), complete_data[test.index,ncol(complete_data)])
```



```{r}
df = data.frame(complete_stand_data[,1:(ncol(complete_stand_data)-1)])
knn_clust = kmeans(df, centers = 3, algorithm = 'MacQueen')
fviz_cluster(knn_clust, data = df, ellipse.type = "norm",
             ellipse.level = 0.8,ggtheme= theme_economist_white(),main = 'KNN Clustering')

df = data.frame(complete_stand_data[,1:(ncol(complete_stand_data)-1)])
knn_clust = kmeans(df, centers =4, algorithm = 'MacQueen')
fviz_cluster(knn_clust, data = df, ellipse.type = "norm",
             ellipse.level = 0.8,ggtheme= theme_economist_white(),main = 'KNN Clustering')

```



```{r}
mean(GSPC_1M_Ret)
adf.test(GSPC_1M_Ret)
hist(GSPC_1M_Ret,breaks = 50)
stl_1M_Ret = stl(GSPC_1M_Ret,'periodic')
plot(stl_1M_Ret)
acf(GSPC_1M_Ret,lag.max = 120)
pacf(GSPC_1M_Ret, lag.max = 120)
arima_1m <- auto.arima(GSPC_1M_Ret)
summary(arima_1m)

output<-forecast(arima_1m,h=12)
plot(output)

L <- length(GSPC_1M_Ret)-120  # shrink the length to avoid row index error
x <- GSPC_1M_Ret[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = 12)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, GSPC_1M_Ret[(L+1):(L+12)])

nn_model <- nnetar(GSPC_1M_Ret[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=12)
accuracy(fc_nn, GSPC_1M_Ret[(L+1):(L+12), 1])
```


```{r}
mean(GSPC_Yearly_Ret)
adf.test(GSPC_Yearly_Ret)
hist(GSPC_Yearly_Ret,breaks = 50)
acf(GSPC_Yearly_Ret,lag.max = 10)
pacf(GSPC_Yearly_Ret, lag.max = 10)
arima_1m <- auto.arima(GSPC_Yearly_Ret)
summary(arima_1m)

output<-forecast(arima_1m,h=2)
plot(output)

L <- length(GSPC_Yearly_Ret)-9  # shrink the length to avoid row index error
x <- GSPC_Yearly_Ret[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = 2)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, GSPC_Yearly_Ret[(L+1):(L+2),1])

nn_model <- nnetar(GSPC_Yearly_Ret[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=2)
accuracy(fc_nn, GSPC_Yearly_Ret[(L+1):(L+2),1])
```


```{r}
mean(complete_data$ICSA40_1D)
adf.test(complete_data$ICSA40_1D)
hist(complete_data$ICSA40_1D,breaks = 50)
stl_12M_Ret = stl(complete_data$ICSA40_1D,'periodic')
plot(stl_12M_Ret)
acf(complete_data$ICSA40_1D,lag.max = 160)
pacf(complete_data$ICSA40_1D, lag.max = 160)
arima_12m <- auto.arima(complete_data$ICSA40_1D)
summary(arima_12m)

output<-forecast(arima_12m,h=4)
plot(output)

```


```{r}
t <- 12
L <- length(complete_data$ICSA40_1D) - 108  # shrink the length to avoid row index error
x <- complete_data$ICSA40_1D[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = t)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, complete_data$ICSA40_1D[(L+1):(L+t)])

nn_model <- nnetar(complete_data$ICSA40_1D[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=t)
accuracy(fc_nn, complete_data$ICSA40_1D[(L+1):(L+t), 1])
plot(fc_nn)
plot(complete_data$ICSA40_1D[1:L+t,1])

```


```{r}
t <- 12
L <- length(complete_data$GSPC.Close) - 22  # shrink the length to avoid row index error
x <- complete_data$GSPC.Close[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = t)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, complete_data$GSPC.Close[(L+1):(L+t)])

nn_model <- nnetar(complete_data$GSPC.Close[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=t)
accuracy(fc_nn, complete_data$GSPC.Close[(L+1):(L+t), 1])
plot(fc_nn)
plot(complete_data$GSPC.Close[1:L+t,1])
```
(0,1,0)(2,0,0)[12] - .8 / .7 / NNAR(13,1,7)[12] - .15 / .46 : -86
(0,1,0)(2,0,0)[12] - .3 / 1.14 / NNAR(13,1,7)[12] - .12 / 1.86 : -102



```{r}
mean(GSPC_12M_Trail_Ret)
adf.test(GSPC_12M_Trail_Ret)
hist(GSPC_12M_Trail_Ret,breaks = 50)
stl_1M_Ret = stl(GSPC_12M_Trail_Ret,'periodic')
plot(stl_1M_Ret)
acf(GSPC_12M_Trail_Ret,lag.max = 140)
pacf(GSPC_12M_Trail_Ret, lag.max = 140)


L <- length(GSPC_12M_Trail_Ret)-24  # shrink the length to avoid row index error
x <- GSPC_12M_Trail_Ret[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = 12)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, GSPC_12M_Trail_Ret[(L+1):(L+12)])

nn_model <- nnetar(GSPC_12M_Trail_Ret[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=12)
accuracy(fc_nn, GSPC_12M_Trail_Ret[(L+1):(L+12), 1])
plot(fc_nn)
plot(GSPC_12M_Trail_Ret[1:(L+12),1])
```



```{r}
z = complete_data$RSI_8M
z = z[complete.cases(z),]
z = rollmeanr(z$RSI_8M,48,fill=NA)
z = z[complete.cases(z),]
z = diff(z$RSI_8M,diff=1,lag=6)
z = z[complete.cases(z),]
mean(z)
adf.test(z)
hist(z,breaks = 50)
stl_1M_Ret = stl(z,'periodic')
plot(stl_1M_Ret)
acf(z,lag.max = 140)
pacf(z, lag.max = 140)
auto.arima(z)



L <- length(z)-20  # shrink the length to avoid row index error
x <- z[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = 12)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, z[(L+1):(L+12)])

nn_model <- nnetar(z[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=12)
accuracy(fc_nn, z[(L+1):(L+12), 1])
plot(fc_nn)
plot(z[1:(L+12),1]

```
(1,0,2)(1,0,0)[12] II
(2,0,0)(0,0,2)[12] III
(2,0,0) I  [What's chosen for the complete period by auto.arima()]

Excellent results that are directionally well-fit with rare divergence/heavy error.  The nnetar seems to outperform in examining the smoothed and then differentiated curve.

```{r}
z = complete_data$RSI_6M
z = z[complete.cases(z),]
z = rollmeanr(z$RSI_6M,36,fill=NA)
z = z[complete.cases(z),]
mean(z)
adf.test(z)
hist(z,breaks = 50)
stl_1M_Ret = stl(z,'periodic')
plot(stl_1M_Ret)
acf(z,lag.max = 140)
pacf(z, lag.max = 140)


L <- length(z)-120  # shrink the length to avoid row index error
x <- z[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = 12)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, z[(L+1):(L+12)])

nn_model <- nnetar(z[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=12)
accuracy(fc_nn, z[(L+1):(L+12), 1])
plot(fc_nn)
plot(z[1:(L+12),1])
```



```{r}
z = data$NYX_MD
z = ROC(z$NYX_MD,24)
z = z[complete.cases(z),]
z = rollmeanr(z$NYX_MD,48,fill=NA)
z = z[complete.cases(z),]
z = diff(z$NYX_MD,diff=1,lag=6)
z = z[complete.cases(z),]
mean(z)
adf.test(z)
hist(z,breaks = 50)
stl_1M_Ret = stl(z,'periodic')
plot(stl_1M_Ret)
acf(z,lag.max = 140)
pacf(z, lag.max = 140)


L <- length(z)-72  # shrink the length to avoid row index error
x <- z[1:L]
fit2<-auto.arima(x)
fc <- forecast(fit2, h = 12)  # the output would have error if the number of row > 1e4
plot(fc)
accuracy(fc, z[(L+1):(L+12)])

nn_model <- nnetar(z[2:L,1])
nn_model$p     # 33
nn_model$P     # 0
nn_model$size  #17 = round((33+0+1)/2) neuron size
fitted.nn<-fitted.nnetar(nn_model)
residuals.nnetar<-residuals.nnetar(nn_model)
sqrt(mean(residuals.nnetar**2,na.rm=T))  # 0.007213
accuracy(nn_model)
fc_nn <- forecast(nn_model, h=12)
accuracy(fc_nn, z[(L+1):(L+12), 1])
plot(fc_nn)
plot(z[1:(L+12),1])
```
(2,0,4) III
(2,0,2) III
(0,0,0)(2,0,0)[12] III [but tends to underperform and be discontinuous from the trend...directionally correct] [DON'T USE IT]

NNAR(27,1,14)[12]
NNAR(5,1,4)[12] II
```{r}

```





