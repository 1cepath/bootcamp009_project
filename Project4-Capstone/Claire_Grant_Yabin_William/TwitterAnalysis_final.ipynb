{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql import Row\nfrom pyspark.sql.types import *\nimport json\nfrom pyspark.ml.feature import MinMaxScaler\nfrom pyspark.ml.linalg import Vectors, VectorUDT\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import rank, col"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["import urllib \nACCESS_KEY = \"AKIAI3V4KTCTOD4CF7IQ\"\n# Encode the Secret Key as that can contain \"/\"\nSECRET_KEY = \"Rtz/fw+eFn83ZdtG4k3HE70eLlFGi3Ghc+vLVfvP\".replace(\"/\", \"%2F\")\n# ENCODED_SECRET_KEY = urllib.quote(SECRET_KEY,\"\")\nAWS_BUCKET_NAME = \"project4capstones3\"\nMOUNT_NAME = \"twitter_246821242_612111\"\n#dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n\ndbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["data = sqlContext.read.json(\"/mnt/%s/2017/06/18/03/project*\"%MOUNT_NAME)"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["#drop missing values\ndata_rm_na = data.filter(data['status_id']!='None')\nprint data_rm_na.count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["features_of_interest = ['rt_status_user_followers_count', \n                        'rt_status_user_friends_count', \n                        'rt_status_user_statuses_count', \n                        'rt_status_retweet_count',\n                        'rt_status_user_listed_count', \n                        'rt_status_user_name',\n                        'rt_status_user_profile_image',\n                        'rt_status_num_user_mentions',\n                        'rt_status_user_id', \n                        'searched_names', \n                        'rt_status_sentMag', \n                        'rt_status_sentScore',\n                        'rt_status_text', \n                        'rt_status_favorite_count']\n\ndf_reduce= data_rm_na.select(features_of_interest)\ndf_reduce = df_reduce.withColumn(\"rt_status_user_followers_count\", df_reduce[\"rt_status_user_followers_count\"].cast(IntegerType()))\ndf_reduce = df_reduce.withColumn(\"rt_status_user_friends_count\", df_reduce[\"rt_status_user_friends_count\"].cast(IntegerType()))\ndf_reduce = df_reduce.withColumn(\"rt_status_user_statuses_count\", df_reduce[\"rt_status_user_statuses_count\"].cast(IntegerType()))\ndf_reduce = df_reduce.withColumn(\"rt_status_retweet_count\", df_reduce[\"rt_status_retweet_count\"].cast(IntegerType()))\ndf_reduce = df_reduce.withColumn(\"rt_status_user_listed_count\", df_reduce[\"rt_status_user_listed_count\"].cast(IntegerType()))\ndf_reduce = df_reduce.withColumn(\"rt_status_favorite_count\", df_reduce[\"rt_status_favorite_count\"].cast(IntegerType()))\ndf_reduce = df_reduce.withColumn(\"rt_status_num_user_mentions\", df_reduce[\"rt_status_num_user_mentions\"].cast(IntegerType()))\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# # ratio_followers_following\n# df_reduce = df_reduce.withColumn('ratio_followers_following',df_reduce.rt_status_user_followers_count/(df_reduce.rt_status_user_friends_count+1)+10)\n# max_ratio_followers_following = df_reduce.select('ratio_followers_following').rdd.flatMap(list).max()\n# df_reduce = df_reduce.withColumn('ratio_followers_following',df_reduce.ratio_followers_following/max_ratio_followers_following)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# followers_count rescale\nmax_user_followers_count = df_reduce.select('rt_status_user_followers_count').rdd.flatMap(list).max()\ndf_reduce = df_reduce.withColumn('rescale_rt_status_user_followers_count',df_reduce.rt_status_user_followers_count/max_user_followers_count)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#listed_count rescale\nmax_listed_count = df_reduce.select('rt_status_user_listed_count').rdd.flatMap(list).max()\ndf_reduce = df_reduce.withColumn('rescale_rt_status_user_listed_count',df_reduce.rt_status_user_listed_count/max_listed_count)\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["#number_of_tweets rescale\nmax_user_statuses_count  = df_reduce.select('rt_status_user_statuses_count').rdd.flatMap(list).max()\ndf_reduce = df_reduce.withColumn('rescale_rt_status_user_statuses_count',df_reduce.rt_status_user_statuses_count/max_user_statuses_count)\n"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# retweets_received rescale\nmax_retweets_received  = df_reduce.select('rt_status_retweet_count').rdd.flatMap(list).max()\ndf_reduce = df_reduce.withColumn('rescale_rt_status_retweet_count',df_reduce.rt_status_retweet_count/max_retweets_received)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# retweets_received rescale\nmax_favorite_count  = df_reduce.select('rt_status_favorite_count').rdd.flatMap(list).max()\ndf_reduce = df_reduce.withColumn('rescale_rt_status_favorite_count',df_reduce.rt_status_favorite_count/max_favorite_count)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["### Influence Score\n\ndf_reduce=df_reduce.withColumn('Influencer_Score',\n                              (df_reduce.rescale_rt_status_retweet_count *10 + \n                              df_reduce.rescale_rt_status_favorite_count * 9 +\n                              df_reduce.rescale_rt_status_user_followers_count *6 + \n                              df_reduce.rescale_rt_status_user_statuses_count * 5 +\n                              df_reduce.rescale_rt_status_user_listed_count* 4 # +\n#                               df_reduce.ratio_followers_following * 3\n                              )/34*10 \n                              )\n\n# max_Influencer_Score =  df_reduce.select('Influencer_Score').rdd.flatMap(list).max()\n# df_reduce = df_reduce.withColumn('Influencer_Score',df_reduce.Influencer_Score/max_Influencer_Score*10)\n\n"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["df_final=df_reduce.groupBy('rt_status_user_id').agg(\n  round(max('Influencer_Score'),2).alias('max_influence_score'),\n  max('rt_status_retweet_count').alias('max_retweet_count'),\n  max('rt_status_user_followers_count').alias('max_follower_count'),\n  max('rt_status_user_friends_count').alias('max_friends_count'),\n  round(avg('rt_status_sentScore'),2).alias('avg_sentiment'),\n  round(avg('rt_status_sentMag'),2).alias('avg_sentMag'),\n  first('rt_status_text').alias('status_text'),\n  first('rt_status_user_name').alias('user_name'),\n  first('rt_status_user_profile_image').alias('profile_image'),\n  first('searched_names').alias('search_name'),).sort('max_influence_score',ascending=False)\n# .show(20,False)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["def sent_class(value1):\n  if value1 >-0.4 and value1 <0.4: return 'Neutral'\n  elif value1 <= -0.4: return 'Negative'\n  elif value1 >= 0.4 : return 'Positive'\n\ndf_reduce_udf = udf(sent_class, StringType())  \ndf_final = df_final.withColumn('sent_class',df_reduce_udf('avg_sentiment'))  \n\n# df_with_cat = df.withColumn(\"category\", udfValueToCategory(\"x1\"))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["df_final.createOrReplaceTempView(\"df_final\")\nneg_influence=spark.sql(\"SELECT * FROM df_final WHERE df_final.sent_class='Negative' LIMIT 5\")\npos_influence=spark.sql(\"SELECT * FROM df_final WHERE df_final.sent_class='Positive' LIMIT 5\")\nneu_influence=spark.sql(\"SELECT * FROM df_final WHERE df_final.sent_class='Neutral' LIMIT 5\")"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["neg_influence.write.saveAsTable('neg_influence',mode='overwrite')\npos_influence.write.saveAsTable('pos_influence',mode='overwrite')\nneu_influence.write.saveAsTable('neu_influence',mode='overwrite')\n\nspark.sql(\"SHOW tables\").show()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["neg_text=spark.sql(\"SELECT df_final.status_text FROM df_final WHERE df_final.sent_class='Negative'\")\npos_text=spark.sql(\"SELECT df_final.status_text FROM df_final WHERE df_final.sent_class='Positive'\")\nneu_text=spark.sql(\"SELECT df_final.status_text FROM df_final WHERE df_final.sent_class='Neutral'\")"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["stopwords = [\"a\", \"about\", \"above\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\",\"although\",\"always\",\"am\",\"among\", \"amongst\", \"amoungst\", \"amount\",  \"an\", \"and\", \"another\", \"any\",\"anyhow\",\"anyone\",\"anything\",\"anyway\", \"anywhere\", \"are\", \"around\", \"as\",  \"at\", \"back\",\"be\",\"became\", \"because\",\"become\",\"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\", \"bottom\",\"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\", \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\", \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\",\"else\", \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\", \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fify\", \"fill\", \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\", \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\", \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"however\", \"hundred\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\", \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\", \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\", \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\", \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\", \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\", \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\", \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\",\"part\", \"per\", \"perhaps\", \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\", \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\", \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\", \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thickv\", \"thin\", \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\", \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\", \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\", \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\", \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\", \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"the\",'i','&amp;','-','']"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["def split_line(s): return s.split()\n\ndef stopword(i):\n  if i in stopwords:\n    return ''\n  else:\n    return i\n\ndf_words_udf = udf(stopword, StringType())  "],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["neg_wordsDF=neg_text.rdd.map(lambda x: x[0])\nneg_words_rdd = neg_wordsDF.flatMap(split_line)\nneg_wordcount = neg_words_rdd.map(lambda word: (word.lower(), 1))\nneg_wc = neg_wordcount.reduceByKey(lambda a, b: a+b)\nneg_wc_df=neg_wc.toDF()\nneg_wc_df = neg_wc_df.withColumn('_2',neg_wc_df['_2'].cast(IntegerType()))\nneg_wc_df_stop= neg_wc_df.withColumn('word',df_words_udf('_1'))\nneg_word_cloud=neg_wc_df_stop.filter(neg_wc_df_stop.word != '').sort('_2',ascending=False).select('word','_2')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["pos_wordsDF=pos_text.rdd.map(lambda x: x[0])\npos_words_rdd = pos_wordsDF.flatMap(split_line)\npos_wordcount = pos_words_rdd.map(lambda word: (word.lower(), 1))\npos_wc = pos_wordcount.reduceByKey(lambda a, b: a+b)\npos_wc_df=pos_wc.toDF()\npos_wc_df = pos_wc_df.withColumn('_2',pos_wc_df['_2'].cast(IntegerType()))\npos_wc_df_stop= pos_wc_df.withColumn('word',df_words_udf('_1'))\npos_word_cloud=pos_wc_df_stop.filter(pos_wc_df_stop.word != '').sort('_2',ascending=False).select('word','_2')"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["neu_wordsDF=neu_text.rdd.map(lambda x: x[0])\nneu_words_rdd = neu_wordsDF.flatMap(split_line)\nneu_wordcount = neu_words_rdd.map(lambda word: (word.lower(), 1))\nneu_wc = neu_wordcount.reduceByKey(lambda a, b: a+b)\nneu_wc_df=neu_wc.toDF()\nneu_wc_df = neu_wc_df.withColumn('_2',neu_wc_df['_2'].cast(IntegerType()))\nneu_wc_df_stop= neu_wc_df.withColumn('word',df_words_udf('_1'))\nneu_word_cloud=neu_wc_df_stop.filter(neu_wc_df_stop.word != '').sort('_2',ascending=False).select('word','_2')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["neg_word_cloud.createOrReplaceTempView(\"temp_neg\")\npos_word_cloud.createOrReplaceTempView(\"temp_pos\")\nneu_word_cloud.createOrReplaceTempView(\"temp_neu\")\n\nneg_word_cloud=spark.sql(\"SELECT * FROM temp_neg LIMIT 20\")\npos_word_cloud=spark.sql(\"SELECT * FROM temp_pos LIMIT 20\")\nneu_word_cloud=spark.sql(\"SELECT * FROM temp_neu LIMIT 20\")"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["neu_word_cloud.write.saveAsTable('neu_word_cloud', mode = 'overwrite')\npos_word_cloud.write.saveAsTable('pos_word_cloud', mode = 'overwrite')\nneg_word_cloud.write.saveAsTable('neg_word_cloud', mode = 'overwrite')"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":25}],"metadata":{"name":"TwitterAnalysis","notebookId":4353267888137912},"nbformat":4,"nbformat_minor":0}
